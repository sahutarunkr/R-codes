# Make sure mxnet is attached, and load in the olivetti_x
# and olivetti_y datasets. 
myData = cbind(olivetti_X,olivetti_y)
dim(myData)

# Here we provide some column names ...
names(myData) <- c(paste("pixel", c(1:784)),"label")
myData[0:3,0:4]

# We will create a simple CV ...
train = sample(1:400,300)
trainData = myData[train,]
testData = myData[-train,]
dim(trainData)

# Here we reformat the data to be of a form that the 
# CNN expects ...
trainData <- data.matrix(trainData)
train_x <- t(trainData[, -4097])
train_y <- trainData[, 4097]
train_array <- train_x
dim(train_array) <- c(64, 64, 1, ncol(train_x))
dim(train_array)

# Here is the test data ...
test_x <- t(testData[, -4097])
test_y <- testData[, 4097]
test_array <- test_x
dim(test_array) <- c(64, 64, 1, ncol(test_x))

# Now we create the CNN ...
data <- mx.symbol.Variable('data')

# 1st convolutional layer
conv_1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
tanh_1 <- mx.symbol.Activation(data = conv_1, act_type = "tanh")
pool_1 <- mx.symbol.Pooling(data = tanh_1, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))

# 2nd convolutional layer
conv_2 <- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)
tanh_2 <- mx.symbol.Activation(data = conv_2, act_type = "tanh")
pool_2 <- mx.symbol.Pooling(data=tanh_2, pool_type = "max", kernel = c(2, 2), stride = c(2, 2))

# 1st fully connected layer
flatten <- mx.symbol.Flatten(data = pool_2)
fc_1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 <- mx.symbol.Activation(data = fc_1, act_type = "tanh")

# 2nd fully connected layer
fc_2 <- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)

# Output. Softmax output since we'd like to get some 
# probabilities.
NN_model <- mx.symbol.SoftmaxOutput(data = fc_2)

# Train the model ... maybe?
devices <- mx.cpu()
model <- mx.model.FeedForward.create(NN_model,
X = train_array,
y = train_y,
ctx = devices,
num.round = 480,
array.batch.size = 40,
learning.rate = 0.01,
momentum = 0.9,
eval.metric = mx.metric.accuracy,
epoch.end.callback = mx.callback.log.train.metric(100))

# Check accuracy ...
predicted <- predict(model, test_array)

# Assign labels
predicted_labels <- max.col(t(predicted)) - 1

# Get accuracy
sum(diag(table(test[, 1], predicted_labels)))/40
