# Read in the credit card dataset
summary(creditcard)
myData = creditcard
dim(myData)
# We will drop the last column (fraud indicator)
# and then do a PCA to reduce dimensions.
# The variables need to be scaled first
myDataPred = myData[,-31]
cc_PCA = prcomp(myDataPred, scale. = TRUE, center = TRUE)
plot(cc_PCA)
# We will use 2 components to start.
cc_PCA_2 = cc_PCA$x[,1:2]
plot(cc_PCA_2)
# We add back, the fraud indicator, and see if the anomalies
# correspond to fraud. We will use a simple method
# at first to ID anomalies
cc_An = as.data.frame(cbind(cc_PCA_2,myData[,31]))
summary(cc_An)
# We create a 4th column to ID anomalies. Our anomalies
# will transactions that are far from the PC means
cc_An$V4=0
PC1Mean = mean(cc_An$PC1)
PC2Mean = mean(cc_An$PC2)
PC1SD = sd(cc_An$PC1)
PC2SD = sd(cc_An$PC2)
PC1_LB = PC1Mean - 2.5*PC1SD
PC1_UB = PC1Mean + 2.5*PC1SD
PC2_LB = PC2Mean - 2.5*PC2SD
PC2_UB = PC2Mean + 2.5*PC2SD
# Here we flip the anomaly bit if the transaction is
# far from the PC means ...
cc_An$V4 = ifelse(((cc_An$PC1 < PC1_LB) | (cc_An$PC1 > PC1_UB)), 1, 0)
summary(cc_An)
table(cc_An$V3,cc_An$V4)
cc_An$V4 = ifelse(((cc_An$PC2 < PC2_LB) | (cc_An$PC2 > PC2_UB)), 1, cc_An$V4)
summary(cc_An)
table(cc_An$V3,cc_An$V4)
cc_An$V4 = as.factor(cc_An$V4)
plot(cc_An$PC1, cc_An$PC2, col=cc_An$V4)
# This approach does not do a good job of identifying
# fraud - we would need to build a predictive model. But
# we did identify unusal transactions.
# To free up memory, you may want to clear the environment
# and plots.
# Let's work with another dataset - load in Ames housing
View(AmesHousing)
summary(AmesHousing)
# Messy dataset that needs cleaning!
myData = AmesHousing
# We remove variables that are mostly NA:
myData$Order=NULL
myData$PID=NULL
myData$MS.SubClass=NULL
myData$Alley=NULL
myData$Fence=NULL
myData$Pool.QC=NULL
myData$Misc.Feature=NULL
myData$Fireplace.Qu=NULL
myData_2=na.omit(myData)
dim(myData_2)
summary(myData_2)
# We have a dataset with mixed data - we will use
# model matrix to create a fully numerical data frame,
# then use PCA to reduce dimensions ...
myData_2_Num=model.matrix(~.,myData_2)
Ames_PCA = prcomp(myData_2_Num, scale. = TRUE, center = TRUE)
# The data frame has a column of zeroes - check the summary:
summary(myData_2)
# Notice there are some factors that have a '0' count for
# a category:
summary(myData_2$Heating)
# We need to identify these and remove:
myData_2_Num = model.matrix(~. -1, myData_2)
myData_3 = myData_2_Num[, colSums(myData_2_Num != 0) > 0]
dim(myData_2_Num)
dim(myData_3)
# Now we can do PCA ...
Ames_PCA = prcomp(myData_3, scale. = TRUE, center = TRUE)
plot(Ames_PCA)
Ames_PCA_2 = Ames_PCA$x[,1:2]
plot(Ames_PCA_2)
# We do a K-Means clustering (2 clusters) ...
KM_Ames_2 = kmeans(Ames_PCA_2,2)
Ames_PCA_2=as.data.frame(cbind(Ames_PCA_2,KM_Ames_2$cluster))
summary(Ames_PCA_2)
names(Ames_PCA_2)[3]<-"Cluster"
# We need to compute the distance from each data point
# to the centroid of the cluster they are in ...
KM_Ames_2$centers
# Here we loop over all rows and add a distance column:
for(index in 1:nrow(Ames_PCA_2))
{
distance = (Ames_PCA_2[index,1] - KM_Ames_2$centers[Ames_PCA_2[index,3],1])**2
distance = distance + (Ames_PCA_2[index,2] - KM_Ames_2$centers[Ames_PCA_2[index,3],2])**2
Ames_PCA_2[index,4] = sqrt(distance)
}
Summary(Ames_PCA_2)
# We will identify anomalies as anything in the outer
# 5% of distance from the center of the cluster ...
quantile(Ames_PCA_2$distance,.95)
Ames_PCA_2$Anomaly = ifelse(Ames_PCA_2$distance > quantile(Ames_PCA_2$distance,.95), 2, 1)
summary(Ames_PCA_2)
plot(Ames_PCA_2$PC1, Ames_PCA_2$PC2, col=Ames_PCA_2$Anomaly)
# We can identify anomalies, but further comparison to the
# orignal dataset will be required to tell why they are
# anomalies ...
creditcard <- read.csv("C:/Users/tarun/OneDrive - The University of Texas at Dallas/Semester 4/R/DataSets/creditcard.csv")
View(creditcard)
creditcard <- read.csv("C:/Users/tarun/OneDrive - The University of Texas at Dallas/Semester 4/R/DataSets/creditcard.csv")
View(creditcard)
View(creditcard)
creditcard <- read.csv("C:/Users/tarun/OneDrive - The University of Texas at Dallas/Semester 4/R/DataSets/creditcard.csv")
creditcard <- read.csv("C:/Users/tarun/OneDrive - The University of Texas at Dallas/Semester 4/R/DataSets/creditcard.csv")
View(creditcard)
myData = creditcard
dim(myData)
myDataPred = myData[,-31]
cc_PCA = prcomp(myDataPred, scale. = TRUE, center = TRUE)
plot(cc_PCA)
myData$Time=NULL
myData$Class=NULL
myDataPred = myData[,-31]
cc_PCA = prcomp(myDataPred, scale. = TRUE, center = TRUE)
plot(cc_PCA)
cc_PCA_2 = cc_PCA$x[,1:2]
plot(cc_PCA_2)
cc_An = as.data.frame(cbind(cc_PCA_2,myData[,31]))
summary(cc_An)
cc_An = as.data.frame(cbind(cc_PCA_2,creditcard[,31]))
summary(cc_An)
cc_An$V4=0
PC1Mean = mean(cc_An$PC1)
PC2Mean = mean(cc_An$PC2)
PC1Mean
PC1SD = sd(cc_An$PC1)
PC2SD = sd(cc_An$PC2)
PC1_LB = PC1Mean - 2.5*PC1SD
PC1_UB = PC1Mean + 2.5*PC1SD
PC2_LB = PC2Mean - 2.5*PC2SD
PC2_UB = PC2Mean + 2.5*PC2SD
cc_An$V4 = ifelse(((cc_An$PC1 < PC1_LB) | (cc_An$PC1 > PC1_UB)), 1, 0)
summary(cc_An)
table(cc_An$V3,cc_An$V4)
cc_An$V4 = ifelse(((cc_An$PC2 < PC2_LB) | (cc_An$PC2 > PC2_UB)), 1, cc_An$V4)
table(cc_An$V3,cc_An$V4)
PC1_LB = PC1Mean - 3*PC1SD
PC1_UB = PC1Mean + 3*PC1SD
PC2_LB = PC2Mean - 3*PC2SD
PC2_UB = PC2Mean + 3*PC2SD
cc_An$V4 = ifelse(((cc_An$PC1 < PC1_LB) | (cc_An$PC1 > PC1_UB)), 1, 0)
summary(cc_An)
table(cc_An$V3,cc_An$V4)
cc_An$V4 = ifelse(((cc_An$PC2 < PC2_LB) | (cc_An$PC2 > PC2_UB)), 1, cc_An$V4)
table(cc_An$V3,cc_An$V4)
summary(cc_An)
PC1_LB = PC1Mean - 3.5*PC1SD
PC1_UB = PC1Mean + 3.5*PC1SD
PC2_LB = PC2Mean - 3.5*PC2SD
PC2_UB = PC2Mean + 3.5*PC2SD
cc_An$V4 = ifelse(((cc_An$PC1 < PC1_LB) | (cc_An$PC1 > PC1_UB)), 1, 0)
summary(cc_An)
cc_An$V4 = ifelse(((cc_An$PC2 < PC2_LB) | (cc_An$PC2 > PC2_UB)), 1, cc_An$V4)
table(cc_An$V3,cc_An$V4)
cc_An$V4 = as.factor(cc_An$V4)
plot(cc_An$PC1, cc_An$PC2, col=cc_An$V4)
PC1_LB = PC1Mean - 2.5*PC1SD
PC1_UB = PC1Mean + 2.5*PC1SD
PC2_LB = PC2Mean - 2.5*PC2SD
PC2_UB = PC2Mean + 2.5*PC2SD
cc_An$V4 = ifelse(((cc_An$PC1 < PC1_LB) | (cc_An$PC1 > PC1_UB)), 1, 0)
summary(cc_An)
cc_An$V4 = as.factor(cc_An$V4)
plot(cc_An$PC1, cc_An$PC2, col=cc_An$V4)
plot(cc_An$PC1, cc_An$PC2, col=cc_An$V4)
View(AmesHousing)
View(AmesHousing)
AmesHousing <- read.delim("C:/Users/tarun/OneDrive - The University of Texas at Dallas/Semester 4/R/DataSets/Lecture-30-Data/AmesHousing.txt")
View(AmesHousing)
myData=AmeHousing
summary(myData)
myData=AmesHousing
summary(myData)
myData$Order=NULL
myData$PID=NULL
myData$MS.SubClass=NULL
myData$Alley=NULL
myData$Fence=NULL
myData$Pool.QC=NULL
myData$Misc.Feature=NULL
myData$Fireplace.Qu=NULL
myData_2=na.omit(myData)
dim(myData_2)
summary(myData_2)
myData_2_Num=model.matrix(~.,myData_2)
dim(myData_2_Num)
Ames_PCA = prcomp(myData_2_Num, scale. = TRUE, center = TRUE)
summary(myData_2)
summary(myData_2$Heating)
myData_2_Num = model.matrix(~. -1, myData_2)
myData_3 = myData_2_Num[, colSums(myData_2_Num != 0) > 0]
myData_2_Num
Ames_PCA = prcomp(myData_3, scale. = TRUE, center = TRUE)
plot(Ames_PCA)
Ames_PCA_2 = Ames_PCA$x[,1:2]
plot(Ames_PCA_2)
KM_Ames_2 = kmeans(Ames_PCA_2,2)
Ames_PCA_2=as.data.frame(cbind(Ames_PCA_2,KM_Ames_2$cluster))
summary(Ames_PCA_2)
names(Ames_PCA_2)[3]<-"Cluster"
for(index in 1:nrow(Ames_PCA_2))
{
distance = (Ames_PCA_2[index,1] - KM_Ames_2$centers[Ames_PCA_2[index,3],1])**2
distance = distance + (Ames_PCA_2[index,2] - KM_Ames_2$centers[Ames_PCA_2[index,3],2])**2
Ames_PCA_2[index,4] = sqrt(distance)
}
quantile(Ames_PCA_2$distance,.95)
Ames_PCA_2$Anomaly = ifelse(Ames_PCA_2$distance > quantile(Ames_PCA_2$distance,.95), 2, 1)
names(Ames_PCA_2)
names(Ames_PCA_2)
quantile(Ames_PCA_2$V4,.95)
Ames_PCA_2$Anomaly = ifelse(Ames_PCA_2$V4 > quantile(Ames_PCA_2$distance,.95), 2, 1)
Ames_PCA_2$Anomaly = ifelse(Ames_PCA_2$V4 > quantile(Ames_PCA_2$V4,.95), 2, 1)
plot(Ames_PCA_2$PC1, Ames_PCA_2$PC2, col=Ames_PCA_2$Anomaly)
auto.mpg <- read.table("C:/Users/tarun/OneDrive - The University of Texas at Dallas/Semester 4/R/DataSets/Lecture-30-Data/auto-mpg.data", quote="\"", comment.char="")
View(auto.mpg)
myData=auto.mpg
cc_PCA = prcomp(myData, scale. = TRUE, center = TRUE)
summary(myData)
myData$v4=as.numeric(myData$V4)
auto_PCA = prcomp(myData, scale. = TRUE, center = TRUE)
myData$v9=NULL
auto_PCA = prcomp(myData, scale. = TRUE, center = TRUE)
summary(myData)
myData$V9=NULL
myData$v4=NULL
myData$V4=as.numeric(myData$V4)
summary(myData)
auto_PCA = prcomp(myData, scale. = TRUE, center = TRUE)
plot(auto_PCA)
Auto_PCA_2=auto_PCA$x[,1:2]
plot(Auto_PCA_2)
KM_Auto_2=kmeasn(Auto_PCA_2,4)
Ames_PCA_2=as.data.frame(cbind(Ames_PCA_2,KM_Ames_2$cluster))
summary(Ames_PCA_2)
Auto_PCA_2=as.data.frame(cbind(Auto_PCA_2,KM_Auto_2$cluster))
KM_Auto_2=kmeasn(Auto_PCA_2,4)
KM_Auto_2=kmeans(Auto_PCA_2,4)
Auto_PCA_2=as.data.frame(cbind(Auto_PCA_2,KM_Auto_2$cluster))
summary(Ames_PCA_2)
summary(Auto_PCA_2)
names(Auto_PCA_2)[3]<-"Cluster"
for(index in 1:nrow(Ames_PCA_2))
{
distance = (Auto_PCA_2[index,1] - KM_Auto_2$centers[Auto_PCA_2[index,3],1])**2
distance = distance + (Auto_PCA_2[index,2] - KM_Auto_2$centers[Auto_PCA_2[index,3],2])**2
Auto_PCA_2[index,4] = sqrt(distance)
}
Summary(Auto_PCA_2)
summary(Auto_PCA_2)
for(index in 1:nrow(Auto_PCA_2))
{
distance = (Auto_PCA_2[index,1] - KM_Auto_2$centers[Auto_PCA_2[index,3],1])**2
distance = distance + (Auto_PCA_2[index,2] - KM_Auto_2$centers[Auto_PCA_2[index,3],2])**2
Auto_PCA_2[index,4] = sqrt(distance)
}
Summary(Auto_PCA_2)
summary(Auto_PCA_2)
myData_3=as.data.frame(cbind(Auto_PCA_2,auto.mpg$V9)
)
quantile(Auto_PCA_2$distance,.95)
Auto_PCA_2
myData_3=as.data.frame(cbind(Auto_PCA_2,auto.mpg$V9)
)
savehistory("C:/Users/tarun/OneDrive - The University of Texas at Dallas/Semester 4/R/Script/auto data order.Rhistory")
